---
layout: post
title: Env(2) Hadoop部署安装
---

参考文档：黑马07-hadoop集群安装操作.doc
采用了较新的版本。

## 1 下载并解压hadoop安装包
[Apache Hadoop](https://hadoop.apache.org/releases.html)，以3.4.1版为例，下载压缩包并传至节点1，解压：
```sh
cd ~/Work/2025
tar -zxvf hadoop-3.4.1.tar.gz -C .
```
更名：
```sh
ln -s hadoop-3.4.1 hadoop
```
## 2 目录结构

第3节要配置的文件均在hadoop/etc/hadoop文件夹下。
## 3 配置文件修改

```sh
cd hadoop/etc/hadoop
```
### 3.1 hadoop-env.sh

`sudo vim ./hadoop-env.sh`，首先修改第54行`54gg`
```sh
export JAVA_HOME=/usr/lib/jvm/java-17-openjdk-amd64
```
在文件末尾添加
```sh
export HDFS_NAMENODE_USER=user
export HDFS_DATANODE_USER=user
export HDFS_SECONDARYNAMENODE_USER=user
export YARN_RESOURCEMANAGER_USER=user
export YARN_NODEMANAGER_USER=user
```
注：原文档的值是root，但我各节点采用的是user用户，所以值改为了user。
### 3.2 core-site.xml

在core-site.xml中添加字段：
```xml
    <property>
        <name>fs.defaultFS</name>
        <value>hdfs://node1:8020</value>
    </property>

    <property>
        <name>hadoop.tmp.dir</name>
        <value>/usr/local/hadoop/tmp</value>
    </property>

    <!-- 设置HDFS web UI用户身份 -->
    <property>
        <name>hadoop.http.staticuser.user</name>
        <value>user</value>
    </property>

    <!-- 整合hive -->
    <property>
        <name>hadoop.proxyuser.root.hosts</name>
        <value>*</value>
    </property>

    <property>
        <name>hadoop.proxyuser.root.groups</name>
        <value>*</value>
    </property>
```
注意，需要创建/usr/local/hadoop/目录并改为user所有：
```sh
sudo mkdir -p /usr/local/hadoop
sudo chown user /usr/local/hadoop/
```
### 3.3 hdfs-site.xml

```xml
    <!-- 指定secondarynamenode运行位置 -->
    <property>
        <name>dfs.namenode.secondary.http-address</name>
        <value>node2:50090</value>
    </property>
```
## 3.4 mapred-site.xml

```xml
    <property>
        <name>mapreduce.framework.name</name>
        <value>yarn</value>
    </property>
    <property>
        <name>yarn.app.mapreduce.am.env</name>
        <value>HADOOP_MAPRED_HOME=${HADOOP_HOME}</value>
    </property>
    <property>
        <name>mapreduce.map.env</name>
        <value>HADOOP_MAPRED_HOME=${HADOOP_HOME}</value>
    </property>
    <property>
        <name>mapreduce.reduce.env</name>
        <value>HADOOP_MAPRED_HOME=${HADOOP_HOME}</value>
    </property>
```
### 3.5 yarn-site.xml

```xml
    <!-- 指定YARN的主角色（ResourceManager）的地址 -->
    <property>
        <name>yarn.resourcemanager.hostname</name>
        <value>node1</value>
    </property>
    <!-- NodeManager上运行的附属服务。需配置成mapreduce_shuffle，才可运行MapReduce程序默认值："" -->
    <property>
        <name>yarn.nodemanager.aux-services</name>
        <value>mapreduce_shuffle</value>
    </property>
    <!-- 是否将对容器实施物理内存限制 -->
    <property>
        <name>yarn.nodemanager.pmem-check-enabled</name>
        <value>false</value>
    </property>
    <!-- 是否将对容器实施虚拟内存限制。 -->
    <property>
        <name>yarn.nodemanager.vmem-check-enabled</name>
        <value>false</value>
    </property>
    <!-- 开启日志聚集 -->
    <property>
        <name>yarn.log-aggregation-enable</name>
        <value>true</value>
    </property>
    <!-- 设置yarn历史服务器地址 -->
    <property>
        <name>yarn.log.server.url</name>
        <value>http://node1:19888/jobhistory/logs</value>
    </property>
    <!-- 保存的时间7天 -->
    <property>
        <name>yarn.log-aggregation.retain-seconds</name>
        <value>604800</value>
    </property>
```
### 3.6 workers

清空之后，添加如下内容：
```
ubuntu-node1
ubuntu-node2
ubuntu-node3
```
### 3.7 yarn-env.sh

如果使用了JDK9.0以上的版本([参考链接](https://blog.csdn.net/qq_46723500/article/details/139044101))，需`sudo vim ~/Work/2025/hadoop/etc/hadoop/yarn-env.sh`，添加下面一行：
```sh
export HADOOP_OPTS="--add-opens java.base/java.lang=ALL-UNNAMED"
```
否则报错：`hadoop module java.base does not “opens java.lang“ to unnamed module_hadoop module java.base does not "opens java.lang`
## 4 同步安装包

在node1端：
```sh
scp -r hadoop-3.4.1/ node2:$PWD
scp -r hadoop-3.4.1/ node3:$PWD
```
在node2和node3端创建软连接：
```
ln -s hadoop-3.4.1/ hadoop
```
## 5 Hadoop环境变量
## 6 Hadoop集群启动

要启动Hadoop集群，需要启动HDFS和YARN两个集群。

注意：**首次启动HDFS时，必须对其进行格式化操作**：
```sh
hadoop namenode -format
```
本质上是一些清理和准备工作，因为此时的HDFS在物理上还是不存在的。
### 6.1 单节点逐个启动

在主节点上使用以下命令启动HDFS NameNode：
```sh
$HADOOP_HOME/bin/hdfs --daemon start namenode
```
在每个从节点上使用以下命令启动HDFS DataNode：
```sh
$HADOOP_HOME/bin/hdfs --daemon start datanode
```
在node2上使用以下命令启动HDFS SecondaryNameNode：
```sh
$HADOOP_HOME/bin/hdfs --daemon start secondarynamenode
```
在主节点上使用以下命令启动YARN ResourceManager：
```sh
$HADOOP_HOME/bin/yarn --daemon start resourcemanager
```
在每个从节点上使用以下命令启动YARN nodemanager：
```sh
$HADOOP_HOME/bin/yarn --daemon start nodemanager
```
如果想要停止某个节点上某个角色，只需要把命令中的**start**改为**stop**即可。
### 6.2 脚本一键启动

如果配置了etc/hadoop/workers和ssh免密登录，则可以使用程序脚本启动所有Hadoop两个集群的相关进程，在主节点所设定的机器上执行。

hdfs：$HADOOP_PREFIX/sbin/start-dfs.sh
yarn: $HADOOP_PREFIX/sbin/start-yarn.sh
停止集群：stop-dfs.sh、stop-yarn.sh
同时还提供了完整的一键化脚本:
start-all.sh 和 stop-all.sh
### 坑
坑1：`INFO util.ExitUtil: Exiting with status 1: java.io.IOException: Cannot create directory /usr/local/hadoop/tmp/dfs/name/current`
问题在于，没有权限：
```sh
sudo chown user /usr/local/hadoop/
```

坑2：.secondarynamenode无法开启(非root用户配置hadoop的终极踩坑教程 - CSDN)
问题在于，配置core-site.xml中的存储路径时使用了网上的存储路径 /usr/local/hadoop。首先，这个路径不存在；其次，它应该有user权限。所以：
```sh
sudo mkdir -p /usr/local/hadoop
# 普通用户没有权限创建此文件夹，sudo会导致目录所有者为root，所以要改为user
sudo chown user /usr/local/hadoop/
```
## 7 启动后的效果

node1：
```sh
user@ubuntu-node1:~/Work/2025$ jps
46933 NameNode
47093 DataNode
52728 NodeManager
52878 Jps
51614 ResourceManager
```
node2：
```sh
user@ubuntu-node2:~/Work/2025$ jps
46465 NodeManager
46613 Jps
45000 DataNode
45933 SecondaryNameNode
```
node3：
```sh
user@ubuntu-node3:~/Work/2025$ jps
42247 DataNode
43161 NodeManager
43277 Jps
```
## 8 集群Web UI

NameNode：(http://192.168.233.129:9870/)
ResourceManager：(http://192.168.233.129:8088/)
如果无法访问ResourceManager，查看8088端口状态：
```sh
user@ubuntu-node1:~$ netstat -nltp | grep 8088
(Not all processes could be identified, non-owned process info
 will not be shown, you would have to be root to see it all.)
tcp6       0      0 127.0.1.1:8088          :::*                    LISTEN      51614/java
```
如果是如图情况，8088端口挂载在127.0.1.1端口下，所以只能本机访问端口。应修改yarn-site.xml。
## 9 MapReduce jobHistory
### 9.1 修改mapred-site.sh
`sudo vim ~/Work/2025/hadoop/etc/hadoop/mapred-site.sh`添加如下内容：
```xml
    <property>
        <name>mapreduce.jobhistory.address</name>
        <value>node1:10020</value>
    </property>
    <property>
        <name>mapreduce.jobhistory.webapp.address</name>
        <value>node1:19888</value>
    </property>
```
### 9.2 分发配置

```sh
cd ~/Work/2025/hadoop/etc/hadoop
scp -r mapred-site.xml node2:$PWD
scp –r mapred-site.xml node3:$PWD
```
### 9.3 启动jobHistoryServer服务进程
```sh
mapred --daemon start historyserver
# mapred --daemon stop historyserver # 关闭
```
## 9.4 页面访问jobhistoryserver
(http://node1:19888/jobhistory)
如果无法访问，在各节点关闭所有进程，重启，即可